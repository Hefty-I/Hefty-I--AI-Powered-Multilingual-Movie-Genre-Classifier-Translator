{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2ba5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\hassa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gradio as gr\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.data.find('corpus/stopwords')\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpus/wordnet')\n",
    "    nltk.data.find('corpus/omw-1.4')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize session state\n",
    "session_state = {\n",
    "    \"preprocessed_data\": None,\n",
    "    \"model\": None,\n",
    "    \"vectorizer\": None,\n",
    "    \"multilabel_binarizer\": None,\n",
    "    \"evaluation_metrics\": None,\n",
    "    \"confusion_matrix\": None,\n",
    "    \"translated_summaries\": {},\n",
    "    \"audio_files\": {},\n",
    "    \"top_genres\": None,\n",
    "    \"has_trained\": False,\n",
    "    \"auto_process\": False\n",
    "}\n",
    "\n",
    "# Define paths to data files\n",
    "plot_summaries_path = \"attached_assets/plot_summaries.txt\"\n",
    "metadata_path = \"attached_assets/movie.metadata.tsv\"\n",
    "\n",
    "# Maximum height limit in pixels (below WebP limit of 16383)\n",
    "MAX_HEIGHT_PIXELS = 15000\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    tokens = text.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def load_and_preprocess_data(plot_summaries_path, metadata_path):\n",
    "    with open(plot_summaries_path, 'r', encoding='utf-8') as f:\n",
    "        plot_summaries_content = f.read()\n",
    "    \n",
    "    plot_summaries_data = []\n",
    "    for line in plot_summaries_content.strip().split('\\n'):\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "            movie_id = parts[0]\n",
    "            summary = parts[1]\n",
    "            plot_summaries_data.append([movie_id, summary])\n",
    "    \n",
    "    df_summaries = pd.DataFrame(plot_summaries_data, columns=['movie_id', 'summary'])\n",
    "    \n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        metadata_content = f.read()\n",
    "    \n",
    "    metadata_data = []\n",
    "    for line in metadata_content.strip().split('\\n'):\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) >= 9:\n",
    "            movie_id = parts[0]\n",
    "            genres = parts[8].split()\n",
    "            genres = [g.strip('{}') for g in genres]\n",
    "            metadata_data.append([movie_id, genres])\n",
    "    \n",
    "    df_metadata = pd.DataFrame(metadata_data, columns=['movie_id', 'genres'])\n",
    "    \n",
    "    df = pd.merge(df_summaries, df_metadata, on='movie_id')\n",
    "    df['processed_summary'] = df['summary'].apply(preprocess_text)\n",
    "    df = df[df['processed_summary'].str.strip() != '']\n",
    "    df = df[df['genres'].apply(len) > 0]\n",
    "    \n",
    "    unique_genres = set()\n",
    "    for genre_list in df['genres']:\n",
    "        unique_genres.update(genre_list)\n",
    "    \n",
    "    selected_movies = []\n",
    "    genre_count = {genre: 0 for genre in unique_genres}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        movie_id = row['movie_id']\n",
    "        genres = row['genres']\n",
    "        needs_more = False\n",
    "        for genre in genres:\n",
    "            if genre_count[genre] < 5:\n",
    "                needs_more = True\n",
    "                break\n",
    "        if needs_more:\n",
    "            selected_movies.append(movie_id)\n",
    "            for genre in genres:\n",
    "                genre_count[genre] += 1\n",
    "    \n",
    "    if len(selected_movies) < 500:\n",
    "        remaining = df[~df['movie_id'].isin(selected_movies)]\n",
    "        additional = min(500 - len(selected_movies), len(remaining))\n",
    "        additional_ids = remaining.head(additional)['movie_id'].tolist()\n",
    "        selected_movies.extend(additional_ids)\n",
    "    \n",
    "    df = df[df['movie_id'].isin(selected_movies)]\n",
    "    df_processed = df[['movie_id', 'summary', 'processed_summary', 'genres']]\n",
    "    \n",
    "    X = df_processed['processed_summary']\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    y = mlb.fit_transform(df_processed['genres'])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return df_processed, X_train, X_test, y_train, y_test, vectorizer, mlb\n",
    "\n",
    "def translate_text(text, target_language):\n",
    "    try:\n",
    "        translator = GoogleTranslator(source='auto', target=target_language)\n",
    "        chunks = [text[i:i+4500] for i in range(0, len(text), 4500)]\n",
    "        translated_chunks = []\n",
    "        for chunk in chunks:\n",
    "            time.sleep(0.5)\n",
    "            translation = translator.translate(chunk)\n",
    "            translated_chunks.append(translation)\n",
    "        return ' '.join(translated_chunks)\n",
    "    except Exception as e:\n",
    "        return f\"Translation error: {str(e)}\"\n",
    "\n",
    "def get_language_name(language_code):\n",
    "    language_map = {'ar': 'Arabic', 'ur': 'Urdu', 'ko': 'Korean'}\n",
    "    return language_map.get(language_code, 'Unknown')\n",
    "\n",
    "def text_to_speech(text, language_code):\n",
    "    debug_info = f\"Input text: {text[:100]}...\\nLanguage code: {language_code}\\n\"\n",
    "    try:\n",
    "        if not text or not isinstance(text, str):\n",
    "            debug_info += \"Error: Input text is empty or invalid.\\n\"\n",
    "            raise ValueError(\"Input text is empty or invalid\")\n",
    "        \n",
    "        language_map = {'ar': 'ar', 'ur': 'ur', 'ko': 'ko'}\n",
    "        tts_lang = language_map.get(language_code, 'en')\n",
    "        debug_info += f\"Mapped TTS language: {tts_lang}\\n\"\n",
    "        \n",
    "        audio_bytes = io.BytesIO()\n",
    "        tts = gTTS(text=text, lang=tts_lang)\n",
    "        tts.write_to_fp(audio_bytes)\n",
    "        audio_bytes.seek(0)\n",
    "        audio_data = audio_bytes.getvalue()\n",
    "        \n",
    "        debug_info += f\"Audio generated successfully, size: {len(audio_data)} bytes\\n\"\n",
    "        return audio_data, debug_info\n",
    "    except Exception as e:\n",
    "        debug_info += f\"Error generating audio: {str(e)}\\n\"\n",
    "        error_audio = io.BytesIO()\n",
    "        error_message = f\"Error generating audio: {str(e)}\"\n",
    "        error_tts = gTTS(text=error_message, lang='en')\n",
    "        error_tts.write_to_fp(error_audio)\n",
    "        error_audio.seek(0)\n",
    "        audio_data = error_audio.getvalue()\n",
    "        debug_info += f\"Error audio generated, size: {len(audio_data)} bytes\\n\"\n",
    "        return audio_data, debug_info\n",
    "\n",
    "def train_genre_model(X_train, X_test, y_train, y_test, model_type='Logistic Regression', hyperparams=None):\n",
    "    if hyperparams is None:\n",
    "        hyperparams = {}\n",
    "    \n",
    "    num_classes = y_train.shape[1]\n",
    "    active_classes = [np.sum(y_train[:, col] > 0) > 0 for col in range(num_classes)]\n",
    "    genre_distribution = {i: np.sum(y_train[:, i]) for i in range(num_classes) if active_classes[i]}\n",
    "    \n",
    "    debug_info = f\"Training with {num_classes} genre classes, {sum(active_classes)} active.\\n\"\n",
    "    debug_info += f\"Hyperparameters: {hyperparams}\\n\"\n",
    "    debug_info += f\"Genre distribution: {genre_distribution}\\n\"\n",
    "    \n",
    "    classifiers = []\n",
    "    for col in range(num_classes):\n",
    "        if not active_classes[col]:\n",
    "            classifiers.append(DummyClassifier(strategy='most_frequent'))\n",
    "        else:\n",
    "            if model_type == 'Logistic Regression':\n",
    "                hyperparams.pop('multi_class', None)\n",
    "                base_model = LogisticRegression(**hyperparams)\n",
    "            elif model_type == 'Random Forest':\n",
    "                base_model = RandomForestClassifier(**hyperparams)\n",
    "            elif model_type == 'Support Vector Machine':\n",
    "                base_model = SVC(**hyperparams)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "            classifiers.append(base_model)\n",
    "    \n",
    "    model = MultiOutputClassifier(estimator=None)\n",
    "    model.estimators_ = classifiers\n",
    "    \n",
    "    for idx, estimator in enumerate(model.estimators_):\n",
    "        estimator.fit(X_train, y_train[:, idx])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision_micro': precision_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        'recall_micro': recall_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        'f1_micro': f1_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    y_test_flat = y_test.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    conf_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "    \n",
    "    return model, metrics, conf_matrix, debug_info\n",
    "\n",
    "def predict_genre(text, model, vectorizer, mlb):\n",
    "    text_features = vectorizer.transform([text])\n",
    "    genre_predictions = model.predict(text_features)\n",
    "    predicted_genres = mlb.inverse_transform(genre_predictions)\n",
    "    return [genre for sublist in predicted_genres for genre in sublist]\n",
    "\n",
    "def get_top_features(vectorizer, model, genre_idx, n=10):\n",
    "    try:\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        if isinstance(model.estimators_[genre_idx], DummyClassifier):\n",
    "            return [(\"No feature importance available for DummyClassifier\", 0)]\n",
    "        if hasattr(model.estimators_[genre_idx], 'feature_importances_'):\n",
    "            coef = model.estimators_[genre_idx].feature_importances_\n",
    "        elif hasattr(model.estimators_[genre_idx], 'coef_'):\n",
    "            coef = model.estimators_[genre_idx].coef_[0]\n",
    "        else:\n",
    "            return [(\"No feature importance available for this model type\", 0)]\n",
    "        feature_coefs = list(zip(feature_names, coef))\n",
    "        feature_coefs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        return feature_coefs[:n]\n",
    "    except Exception as e:\n",
    "        return [(\"Error getting features\", 0)]\n",
    "\n",
    "def display_metrics(metrics):\n",
    "    return f\"\"\"\n",
    "    Accuracy: {metrics['accuracy']:.4f}\n",
    "    Precision (micro): {metrics['precision_micro']:.4f}\n",
    "    Recall (micro): {metrics['recall_micro']:.4f}\n",
    "    F1 Score (micro): {metrics['f1_micro']:.4f}\n",
    "    Precision (macro): {metrics['precision_macro']:.4f}\n",
    "    Recall (macro): {metrics['recall_macro']:.4f}\n",
    "    F1 Score (macro): {metrics['f1_macro']:.4f}\n",
    "    \"\"\"\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    debug_info = f\"Confusion matrix shape: {conf_matrix.shape}\\nValues:\\n{conf_matrix}\\n\"\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={\"size\": 12})\n",
    "        ax.set_title(\"Confusion Matrix (Multi-label)\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        height_in_pixels = fig.get_figheight() * fig.dpi\n",
    "        debug_info += f\"Figure height: {height_in_pixels} pixels\\n\"\n",
    "        return fig, debug_info\n",
    "    except Exception as e:\n",
    "        debug_info += f\"Error plotting confusion matrix: {str(e)}\\n\"\n",
    "        return None, debug_info\n",
    "\n",
    "def plot_genre_distribution(genres):\n",
    "    genre_counts = pd.Series(genres).value_counts()\n",
    "    debug_info = f\"Genre counts:\\n{genre_counts.to_dict()}\\n\"\n",
    "    try:\n",
    "        num_items = len(genre_counts)\n",
    "        base_height = max(6, num_items * 0.3)\n",
    "        max_height = min(base_height, MAX_HEIGHT_PIXELS / 100)  # Convert to inches (assuming 100 dpi)\n",
    "        fig, ax = plt.subplots(figsize=(12, max_height))\n",
    "        sns.barplot(x=genre_counts.values, y=genre_counts.index, ax=ax)\n",
    "        ax.set_title(\"Genre Distribution\")\n",
    "        ax.set_xlabel(\"Count\")\n",
    "        ax.set_ylabel(\"Genre\")\n",
    "        ax.tick_params(axis='y', labelsize=10 if num_items <= 50 else 8)\n",
    "        plt.tight_layout()\n",
    "        height_in_pixels = fig.get_figheight() * fig.dpi\n",
    "        debug_info += f\"Number of genres: {num_items}\\nFigure height: {height_in_pixels} pixels\\n\"\n",
    "        if height_in_pixels > MAX_HEIGHT_PIXELS:\n",
    "            debug_info += \"Warning: Figure height exceeds WebP limit, capped to maximum allowed.\\n\"\n",
    "        return fig, debug_info\n",
    "    except Exception as e:\n",
    "        debug_info += f\"Error plotting genre distribution: {str(e)}\\n\"\n",
    "        return None, debug_info\n",
    "\n",
    "def auto_process_data():\n",
    "    if os.path.exists(plot_summaries_path) and os.path.exists(metadata_path) and not session_state[\"has_trained\"] and not session_state[\"auto_process\"]:\n",
    "        session_state[\"auto_process\"] = True\n",
    "        df_processed, X_train, X_test, y_train, y_test, vectorizer, mlb = load_and_preprocess_data(\n",
    "            plot_summaries_path, metadata_path\n",
    "        )\n",
    "        session_state[\"preprocessed_data\"] = {\n",
    "            \"df_processed\": df_processed,\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test,\n",
    "        }\n",
    "        session_state[\"vectorizer\"] = vectorizer\n",
    "        session_state[\"multilabel_binarizer\"] = mlb\n",
    "        model, evaluation_metrics, conf_matrix, debug_info = train_genre_model(\n",
    "            X_train, X_test, y_train, y_test, \"Logistic Regression\", {\"C\": 1.0, \"max_iter\": 100, \"solver\": \"liblinear\"}\n",
    "        )\n",
    "        session_state[\"model\"] = model\n",
    "        session_state[\"evaluation_metrics\"] = evaluation_metrics\n",
    "        session_state[\"confusion_matrix\"] = conf_matrix\n",
    "        session_state[\"has_trained\"] = True\n",
    "        session_state[\"top_genres\"] = mlb.classes_\n",
    "        return f\"Data processing and model training completed successfully!\\n{debug_info}\"\n",
    "    return \"Data already processed or files not found.\"\n",
    "\n",
    "def welcome_page():\n",
    "    welcome_text = \"\"\"\n",
    "    ## Overview\n",
    "    Welcome to Filmception - an AI-powered system for processing movie summaries, predicting movie genres, \n",
    "    and converting movie summaries into audio formats in multiple languages.\n",
    "    \n",
    "    ### Features:\n",
    "    - Automatically preprocess and clean movie summaries from the CMU Movie Summary dataset\n",
    "    - Translate movie summaries into multiple languages (Arabic, Urdu, Korean)\n",
    "    - Convert translated summaries to audio\n",
    "    - Predict movie genres based on summaries using machine learning\n",
    "    \n",
    "    ### How to use:\n",
    "    1. **Model Training**: Train a machine learning model to predict movie genres\n",
    "    2. **Explore Features**: Analyze the model features and performance\n",
    "    3. **Use the App**: Input your own movie summary and explore the features\n",
    "    4. **Project Report**: View detailed information about the project\n",
    "    \n",
    "    The data is automatically processed when you start the application!\n",
    "    \"\"\"\n",
    "    if session_state[\"preprocessed_data\"] is not None:\n",
    "        df = session_state[\"preprocessed_data\"][\"df_processed\"]\n",
    "        all_genres = []\n",
    "        for genres in df['genres']:\n",
    "            all_genres.extend(genres)\n",
    "        metrics = f\"\"\"\n",
    "        Total Movies: {len(df)}\n",
    "        Unique Genres: {len(set(all_genres))}\n",
    "        Avg. Genres per Movie: {round(len(all_genres) / len(df), 2)}\n",
    "        \"\"\"\n",
    "        fig, plot_debug = plot_genre_distribution(all_genres)\n",
    "        status = \"âœ… Data processing and model training completed successfully!\" if session_state[\"has_trained\"] else \"Data processing completed. Train a model in the 'Model Training' tab.\"\n",
    "        return welcome_text, metrics, fig, status, plot_debug\n",
    "    return welcome_text, \"Data processing in progress...\", None, \"Processing data...\", \"No plot data yet.\"\n",
    "\n",
    "def train_model_page(c_value, max_iter, solver):\n",
    "    if session_state[\"preprocessed_data\"] is None:\n",
    "        return \"Please complete data preprocessing first.\", None, None, None, \"No plot data yet.\"\n",
    "    \n",
    "    hyperparams = {\"C\": c_value, \"max_iter\": int(max_iter), \"solver\": solver}\n",
    "    X_train = session_state[\"preprocessed_data\"][\"X_train\"]\n",
    "    X_test = session_state[\"preprocessed_data\"][\"X_test\"]\n",
    "    y_train = session_state[\"preprocessed_data\"][\"y_train\"]\n",
    "    y_test = session_state[\"preprocessed_data\"][\"y_test\"]\n",
    "    mlb = session_state[\"multilabel_binarizer\"]\n",
    "    \n",
    "    model, evaluation_metrics, conf_matrix, debug_info = train_genre_model(\n",
    "        X_train, X_test, y_train, y_test, \"Logistic Regression\", hyperparams\n",
    "    )\n",
    "    \n",
    "    session_state[\"model\"] = model\n",
    "    session_state[\"evaluation_metrics\"] = evaluation_metrics\n",
    "    session_state[\"confusion_matrix\"] = conf_matrix\n",
    "    session_state[\"has_trained\"] = True\n",
    "    session_state[\"top_genres\"] = mlb.classes_\n",
    "    \n",
    "    fig, plot_debug = plot_confusion_matrix(conf_matrix)\n",
    "    return \"Model training completed!\", display_metrics(evaluation_metrics), fig, debug_info, plot_debug\n",
    "\n",
    "def explore_features_page(selected_genre):\n",
    "    if not session_state[\"has_trained\"]:\n",
    "        return \"Please train a model first.\", None, None, \"No plot data yet.\"\n",
    "    \n",
    "    vectorizer = session_state[\"vectorizer\"]\n",
    "    model = session_state[\"model\"]\n",
    "    top_genres = session_state[\"top_genres\"]\n",
    "    \n",
    "    debug_info = f\"Top genres: {top_genres}\\nSelected genre: {selected_genre}\"\n",
    "    \n",
    "    if top_genres is None or len(top_genres) == 0:\n",
    "        return f\"No genres available. Please train a model first.\\n{debug_info}\", None, None, \"No plot data yet.\"\n",
    "    if selected_genre is None or selected_genre not in top_genres:\n",
    "        return f\"Invalid or no genre selected. Please select a valid genre.\\n{debug_info}\", None, None, \"No plot data yet.\"\n",
    "    \n",
    "    genre_idx = np.where(top_genres == selected_genre)[0][0]\n",
    "    top_words = get_top_features(vectorizer, model, genre_idx, n=20)\n",
    "    \n",
    "    if len(top_words) == 1 and top_words[0][0].startswith(\"No feature\"):\n",
    "        return f\"{top_words[0][0]}\\n{debug_info}\", None, None, \"No plot data due to feature extraction error.\"\n",
    "    \n",
    "    top_words_sorted = sorted(top_words, key=lambda x: x[1])\n",
    "    words = [word for word, coef in top_words_sorted]\n",
    "    coefs = [coef for word, coef in top_words_sorted]\n",
    "    \n",
    "    plot_debug = f\"Top words: {words}\\nCoefficients: {coefs}\\n\"\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        sns.barplot(x=coefs, y=words, hue=words, palette=\"viridis\", ax=ax, legend=False)\n",
    "        ax.set_title(f\"Top 20 Words Associated with {selected_genre}\")\n",
    "        ax.set_xlabel(\"Coefficient Value\")\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "        plt.tight_layout()\n",
    "        height_in_pixels = fig.get_figheight() * fig.dpi\n",
    "        plot_debug += f\"Figure height: {height_in_pixels} pixels\\n\"\n",
    "    except Exception as e:\n",
    "        plot_debug += f\"Error plotting top words: {str(e)}\\n\"\n",
    "        return f\"Error plotting top words.\\n{debug_info}\", None, None, plot_debug\n",
    "    \n",
    "    df = session_state[\"preprocessed_data\"][\"df_processed\"]\n",
    "    sample_idx = np.random.randint(0, len(df))\n",
    "    sample = df.iloc[sample_idx]\n",
    "    preprocessed_text = preprocess_text(sample['summary'])\n",
    "    predicted_genres = predict_genre(\n",
    "        preprocessed_text, model, vectorizer, session_state[\"multilabel_binarizer\"]\n",
    "    )\n",
    "    \n",
    "    sample_text = f\"\"\"\n",
    "    **Movie Summary:** {sample['summary']}\n",
    "    **Actual Genres:** {', '.join(sample['genres'])}\n",
    "    **Predicted Genres:** {', '.join(predicted_genres)}\n",
    "    \"\"\"\n",
    "    \n",
    "    return f\"Top words for {selected_genre}\\n{debug_info}\", fig, sample_text, plot_debug\n",
    "\n",
    "def use_app_page(summary, action, target_language):\n",
    "    if not summary:\n",
    "        return \"Please enter a movie summary.\", None, None, None, \"No plot data due to empty summary.\"\n",
    "    \n",
    "    preprocessed_input = preprocess_text(summary)\n",
    "    \n",
    "    if action == \"Predict Genre\":\n",
    "        if not session_state[\"has_trained\"]:\n",
    "            return \"Please train a model first.\", None, None, None, \"No plot data due to untrained model.\"\n",
    "        predicted_genres = predict_genre(\n",
    "            preprocessed_input, session_state[\"model\"], session_state[\"vectorizer\"], session_state[\"multilabel_binarizer\"]\n",
    "        )\n",
    "        plot_debug = f\"Predicted genres: {predicted_genres}\\n\"\n",
    "        try:\n",
    "            if not predicted_genres:\n",
    "                plot_debug += \"No genres predicted.\\n\"\n",
    "                fig, ax = plt.subplots(figsize=(8, 4))\n",
    "                ax.text(0.5, 0.5, \"No genres predicted\", ha='center', va='center')\n",
    "                ax.set_title(\"Predicted Movie Genres\")\n",
    "                ax.axis('off')\n",
    "            else:\n",
    "                num_items = len(predicted_genres)\n",
    "                base_height = max(4, num_items * 0.5)\n",
    "                max_height = min(base_height, MAX_HEIGHT_PIXELS / 100)  # Convert to inches (assuming 100 dpi)\n",
    "                fig, ax = plt.subplots(figsize=(8, max_height))\n",
    "                ax.barh(range(num_items), [1] * num_items, height=0.5, color='skyblue')\n",
    "                ax.set_yticks(range(num_items))\n",
    "                ax.set_yticklabels(predicted_genres, fontsize=10)\n",
    "                ax.set_title(\"Predicted Movie Genres\")\n",
    "                ax.set_xlabel(\"Confidence\")\n",
    "                ax.set_xlim(0, 1.5)\n",
    "                plt.tight_layout()\n",
    "            height_in_pixels = fig.get_figheight() * fig.dpi\n",
    "            plot_debug += f\"Number of genres: {num_items}\\nFigure height: {height_in_pixels} pixels\\n\"\n",
    "            if height_in_pixels > MAX_HEIGHT_PIXELS:\n",
    "                plot_debug += \"Warning: Figure height exceeds WebP limit, capped to maximum allowed.\\n\"\n",
    "        except Exception as e:\n",
    "            plot_debug += f\"Error plotting predicted genres: {str(e)}\\n\"\n",
    "            return \"Error plotting predicted genres.\", None, None, None, plot_debug\n",
    "        return f\"Predicted Genres: {', '.join(predicted_genres)}\", fig, None, \"No audio for genre prediction.\", plot_debug\n",
    "    \n",
    "    elif action == \"Translate & Audio\":\n",
    "        language_codes = {\"Arabic\": \"ar\", \"Urdu\": \"ur\", \"Korean\": \"ko\"}\n",
    "        language_code = language_codes[target_language]\n",
    "        \n",
    "        debug_info = f\"Translating to {target_language} (code: {language_code})\\n\"\n",
    "        \n",
    "        if summary not in session_state[\"translated_summaries\"] or language_code not in session_state[\"translated_summaries\"][summary]:\n",
    "            translated_text = translate_text(summary, language_code)\n",
    "            session_state[\"translated_summaries\"].setdefault(summary, {})[language_code] = translated_text\n",
    "        else:\n",
    "            translated_text = session_state[\"translated_summaries\"][summary][language_code]\n",
    "        \n",
    "        debug_info += f\"Translated text: {translated_text[:100]}...\\n\"\n",
    "        \n",
    "        if \"Translation error\" in translated_text:\n",
    "            return translated_text, None, None, debug_info, \"No plot for translation action.\"\n",
    "        \n",
    "        # Clear audio cache to force fresh generation\n",
    "        key = f\"{summary}_{language_code}\"\n",
    "        session_state[\"audio_files\"].pop(key, None)\n",
    "        \n",
    "        audio_bytes, audio_debug = text_to_speech(translated_text, language_code)\n",
    "        session_state[\"audio_files\"][key] = audio_bytes\n",
    "        debug_info += audio_debug\n",
    "        \n",
    "        return f\"Translation ({target_language}): {translated_text}\", None, audio_bytes, debug_info, \"No plot for translation action.\"\n",
    "\n",
    "def project_report_page():\n",
    "    report_text = \"\"\"\n",
    "    ## Filmception Project Report\n",
    "    \n",
    "    ### Project Overview\n",
    "    Filmception is an AI-powered tool that combines natural language processing, machine learning, and audio generation \n",
    "    to provide a comprehensive solution for movie summary analysis. It automatically processes movie data from the \n",
    "    CMU Movie Summary Corpus, extracts patterns and insights from movie plots, and offers multilingual support \n",
    "    for translations and audio generation.\n",
    "    \n",
    "    ### Core Components\n",
    "    1. **Data Processing Pipeline**\n",
    "       - Automatic loading of CMU Movie Summary dataset files\n",
    "       - Text preprocessing with efficient tokenization and stop-word removal\n",
    "       - Multi-label genre encoding for machine learning compatibility\n",
    "    2. **Machine Learning Model**\n",
    "       - Genre prediction using multi-label classification\n",
    "       - Support for multiple model types (Logistic Regression, Random Forest, SVM)\n",
    "       - Feature importance analysis to understand genre-specific keywords\n",
    "    3. **Multilingual Support**\n",
    "       - Translation to multiple languages (Arabic, Urdu, Korean)\n",
    "       - Text-to-speech conversion for accessibility\n",
    "       - Audio file generation and download\n",
    "    4. **User Interface**\n",
    "       - Interactive web application built with Gradio\n",
    "       - Dynamic visualization of model metrics and features\n",
    "       - Seamless user experience with automatic data processing\n",
    "    \"\"\"\n",
    "    if session_state[\"preprocessed_data\"] is not None:\n",
    "        df = session_state[\"preprocessed_data\"][\"df_processed\"]\n",
    "        all_genres = []\n",
    "        for genres in df['genres']:\n",
    "            all_genres.extend(genres)\n",
    "        fig, plot_debug = plot_genre_distribution(all_genres)\n",
    "        metrics = f\"\"\"\n",
    "        Total Movies: {len(df)}\n",
    "        Unique Genres: {len(set(all_genres))}\n",
    "        Avg. Genres per Movie: {round(len(all_genres) / len(df), 2)}\n",
    "        \"\"\"\n",
    "        return report_text, fig, metrics, plot_debug\n",
    "    return report_text, None, \"No data available.\", \"No plot data yet.\"\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸŽ¬ Filmception\")\n",
    "    gr.Markdown(\"AI-powered Multilingual movie summary translator and genre classifier\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Welcome\"):\n",
    "            welcome_text = gr.Markdown()\n",
    "            metrics_output = gr.Textbox(label=\"Dataset Statistics\")\n",
    "            status_output = gr.Textbox(label=\"Status\")\n",
    "            genre_plot = gr.Plot()\n",
    "            plot_debug_welcome = gr.Textbox(label=\"Plot Debug Info\")\n",
    "            \n",
    "            gr.Button(\"Load Data\").click(\n",
    "                fn=auto_process_data,\n",
    "                outputs=status_output\n",
    "            ).then(\n",
    "                fn=welcome_page,\n",
    "                outputs=[welcome_text, metrics_output, genre_plot, status_output, plot_debug_welcome]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"Model Training\"):\n",
    "            c_value = gr.Slider(0.1, 10.0, value=1.0, step=0.1, label=\"C (Regularization parameter)\")\n",
    "            max_iter = gr.Slider(100, 1000, value=100, step=50, label=\"Maximum Iterations\")\n",
    "            solver = gr.Dropdown([\"liblinear\", \"saga\"], label=\"Solver\", value=\"liblinear\")\n",
    "            train_button = gr.Button(\"Train Model\")\n",
    "            train_status = gr.Textbox(label=\"Training Status\")\n",
    "            metrics_output = gr.Textbox(label=\"Evaluation Metrics\")\n",
    "            conf_matrix_plot = gr.Plot()\n",
    "            debug_output = gr.Textbox(label=\"Debug Info\")\n",
    "            plot_debug_train = gr.Textbox(label=\"Plot Debug Info\")\n",
    "            \n",
    "            train_button.click(\n",
    "                fn=train_model_page,\n",
    "                inputs=[c_value, max_iter, solver],\n",
    "                outputs=[train_status, metrics_output, conf_matrix_plot, debug_output, plot_debug_train]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"Explore Features\"):\n",
    "            genre_selector = gr.Dropdown(choices=[], label=\"Select Genre\", value=None)\n",
    "            explore_status = gr.Textbox(label=\"Feature Analysis\")\n",
    "            feature_plot = gr.Plot()\n",
    "            sample_output = gr.Markdown(label=\"Sample Prediction\")\n",
    "            plot_debug_explore = gr.Textbox(label=\"Plot Debug Info\")\n",
    "            \n",
    "            def update_genre_dropdown():\n",
    "                if session_state[\"top_genres\"] is not None and len(session_state[\"top_genres\"]) > 0:\n",
    "                    return gr.update(choices=list(session_state[\"top_genres\"]), value=session_state[\"top_genres\"][0])\n",
    "                return gr.update(choices=[], value=None)\n",
    "            \n",
    "            gr.Button(\"Refresh Genres\").click(\n",
    "                fn=update_genre_dropdown,\n",
    "                outputs=genre_selector\n",
    "            ).then(\n",
    "                fn=explore_features_page,\n",
    "                inputs=genre_selector,\n",
    "                outputs=[explore_status, feature_plot, sample_output, plot_debug_explore]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"Use the App\"):\n",
    "            summary_input = gr.Textbox(lines=5, label=\"Enter a Movie Summary\")\n",
    "            action_selector = gr.Dropdown([\"Predict Genre\", \"Translate & Audio\"], label=\"Action\")\n",
    "            language_selector = gr.Dropdown([\"Arabic\", \"Urdu\", \"Korean\"], label=\"Target Language\")\n",
    "            app_button = gr.Button(\"Process\")\n",
    "            app_status = gr.Textbox(label=\"Result\")\n",
    "            app_plot = gr.Plot()\n",
    "            audio_output = gr.Audio(label=\"Audio Playback\")\n",
    "            audio_debug = gr.Textbox(label=\"Audio Debug Info\")\n",
    "            plot_debug_app = gr.Textbox(label=\"Plot Debug Info\")\n",
    "            \n",
    "            app_button.click(\n",
    "                fn=use_app_page,\n",
    "                inputs=[summary_input, action_selector, language_selector],\n",
    "                outputs=[app_status, app_plot, audio_output, audio_debug, plot_debug_app]\n",
    "            )\n",
    "        \n",
    "        with gr.TabItem(\"Project Report\"):\n",
    "            report_text = gr.Markdown()\n",
    "            report_plot = gr.Plot()\n",
    "            report_metrics = gr.Textbox(label=\"Dataset Statistics\")\n",
    "            plot_debug_report = gr.Textbox(label=\"Plot Debug Info\")\n",
    "            \n",
    "            gr.Button(\"Load Report\").click(\n",
    "                fn=project_report_page,\n",
    "                outputs=[report_text, report_plot, report_metrics, plot_debug_report]\n",
    "            )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
